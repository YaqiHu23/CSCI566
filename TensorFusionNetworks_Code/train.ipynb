{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from model import TFN\n",
    "from utils import MultimodalDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(options):\n",
    "    # parse the input args\n",
    "    dataset = options['dataset']\n",
    "    epochs = options['epochs']\n",
    "    model_path = options['model_path']\n",
    "    max_len = options['max_len']\n",
    "\n",
    "    # prepare the paths for storing models\n",
    "    model_path = os.path.join(\n",
    "        model_path, \"tfn.pt\")\n",
    "    print(\"Temp location for saving model: {}\".format(model_path))\n",
    "\n",
    "    # prepare the datasets\n",
    "    print(\"Currently using {} dataset.\".format(dataset))\n",
    "    mosi = MultimodalDataset(dataset, max_len=max_len)\n",
    "    train_set, valid_set, test_set = mosi.train_set, mosi.valid_set, mosi.test_set\n",
    "\n",
    "    audio_dim = train_set[0][0].shape[1]\n",
    "    print(\"Audio feature dimension is: {}\".format(audio_dim))\n",
    "    visual_dim = train_set[0][1].shape[1]\n",
    "    print(\"Visual feature dimension is: {}\".format(visual_dim))\n",
    "    text_dim = train_set[0][2].shape[1]\n",
    "    print(\"Text feature dimension is: {}\".format(text_dim))\n",
    "    input_dims = (audio_dim, visual_dim, text_dim)\n",
    "\n",
    "    # normalize the visual features\n",
    "    visual_max = np.max(np.max(np.abs(train_set.visual), axis=0), axis=0)\n",
    "    visual_max[visual_max==0] = 1\n",
    "    train_set.visual = train_set.visual / visual_max\n",
    "    valid_set.visual = valid_set.visual / visual_max\n",
    "    test_set.visual = test_set.visual / visual_max\n",
    "\n",
    "    # for visual and audio modality, we average across time\n",
    "    # here the original data has shape (max_len, num_examples, feature_dim)\n",
    "    # after averaging they become (1, num_examples, feature_dim)\n",
    "    train_set.visual = np.mean(train_set.visual, axis=0, keepdims=True)\n",
    "    train_set.audio = np.mean(train_set.audio, axis=0, keepdims=True)\n",
    "    valid_set.visual = np.mean(valid_set.visual, axis=0, keepdims=True)\n",
    "    valid_set.audio = np.mean(valid_set.audio, axis=0, keepdims=True)\n",
    "    test_set.visual = np.mean(test_set.visual, axis=0, keepdims=True)\n",
    "    test_set.audio = np.mean(test_set.audio, axis=0, keepdims=True)\n",
    "\n",
    "    # remove possible NaN values\n",
    "    train_set.visual[train_set.visual != train_set.visual] = 0\n",
    "    valid_set.visual[valid_set.visual != valid_set.visual] = 0\n",
    "    test_set.visual[test_set.visual != test_set.visual] = 0\n",
    "\n",
    "    train_set.audio[train_set.audio != train_set.audio] = 0\n",
    "    valid_set.audio[valid_set.audio != valid_set.audio] = 0\n",
    "    test_set.audio[test_set.audio != test_set.audio] = 0\n",
    "\n",
    "    return train_set, valid_set, test_set, input_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(test_loss, test_binacc, test_precision, test_recall, test_f1, test_septacc, test_corr):\n",
    "    print(\"MAE on test set is {}\".format(test_loss))\n",
    "    print(\"Binary accuracy on test set is {}\".format(test_binacc))\n",
    "    print(\"Precision on test set is {}\".format(test_precision))\n",
    "    print(\"Recall on test set is {}\".format(test_recall))\n",
    "    print(\"F1 score on test set is {}\".format(test_f1))\n",
    "    print(\"Seven-class accuracy on test set is {}\".format(test_septacc))\n",
    "    print(\"Correlation w.r.t human evaluation on test set is {}\".format(test_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(options):\n",
    "    DTYPE = torch.FloatTensor\n",
    "    train_set, valid_set, test_set, input_dims = preprocess(options)\n",
    "\n",
    "    model = TFN(input_dims, (4, 16, 128), 64, (0.3, 0.3, 0.3, 0.3), 32)\n",
    "    if options['cuda']:\n",
    "        model = model.cuda()\n",
    "        DTYPE = torch.cuda.FloatTensor\n",
    "    print(\"Model initialized\")\n",
    "    criterion = nn.L1Loss(size_average=False)\n",
    "    optimizer = optim.Adam(list(model.parameters())[2:]) # don't optimize the first 2 params, they should be fixed (output_range and shift)\n",
    "    \n",
    "    # setup training\n",
    "    complete = True\n",
    "    min_valid_loss = float('Inf')\n",
    "    batch_sz = options['batch_size']\n",
    "    patience = options['patience']\n",
    "    epochs = options['epochs']\n",
    "    model_path = options['model_path']\n",
    "    train_iterator = DataLoader(train_set, batch_size=batch_sz, num_workers=4, shuffle=True)\n",
    "    valid_iterator = DataLoader(valid_set, batch_size=len(valid_set), num_workers=4, shuffle=True)\n",
    "    test_iterator = DataLoader(test_set, batch_size=len(test_set), num_workers=4, shuffle=True)\n",
    "    curr_patience = patience\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_iterator:\n",
    "            model.zero_grad()\n",
    "\n",
    "            # the provided data has format [batch_size, seq_len, feature_dim] or [batch_size, 1, feature_dim]\n",
    "            x = batch[:-1]\n",
    "            x_a = Variable(x[0].float().type(DTYPE), requires_grad=False).squeeze()\n",
    "            x_v = Variable(x[1].float().type(DTYPE), requires_grad=False).squeeze()\n",
    "            x_t = Variable(x[2].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(batch[-1].view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            output = model(x_a, x_v, x_t)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            train_loss += loss.data[0] / len(train_set)\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Epoch {} complete! Average Training loss: {}\".format(e, train_loss))\n",
    "\n",
    "        # Terminate the training process if run into NaN\n",
    "        if np.isnan(train_loss):\n",
    "            print(\"Training got into NaN values...\\n\\n\")\n",
    "            complete = False\n",
    "            break\n",
    "\n",
    "        # On validation set we don't have to compute metrics other than MAE and accuracy\n",
    "        model.eval()\n",
    "        for batch in valid_iterator:\n",
    "            x = batch[:-1]\n",
    "            x_a = Variable(x[0].float().type(DTYPE), requires_grad=False).squeeze()\n",
    "            x_v = Variable(x[1].float().type(DTYPE), requires_grad=False).squeeze()\n",
    "            x_t = Variable(x[2].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(batch[-1].view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            output = model(x_a, x_v, x_t)\n",
    "            valid_loss = criterion(output, y)\n",
    "        output_valid = output.cpu().data.numpy().reshape(-1)\n",
    "        y = y.cpu().data.numpy().reshape(-1)\n",
    "\n",
    "        if np.isnan(valid_loss.data[0]):\n",
    "            print(\"Training got into NaN values...\\n\\n\")\n",
    "            complete = False\n",
    "            break\n",
    "\n",
    "        valid_binacc = accuracy_score(output_valid>=0, y>=0)\n",
    "\n",
    "        print(\"Validation loss is: {}\".format(valid_loss.data[0] / len(valid_set)))\n",
    "        print(\"Validation binary accuracy is: {}\".format(valid_binacc))\n",
    "\n",
    "        if (valid_loss.data[0] < min_valid_loss):\n",
    "            curr_patience = patience\n",
    "            min_valid_loss = valid_loss.data[0]\n",
    "            torch.save(model, model_path)\n",
    "            print(\"Found new best model, saving to disk...\")\n",
    "        else:\n",
    "            curr_patience -= 1\n",
    "        \n",
    "        if curr_patience <= 0:\n",
    "            break\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    if complete:\n",
    "        \n",
    "        best_model = torch.load(model_path)\n",
    "        best_model.eval()\n",
    "        for batch in test_iterator:\n",
    "            x = batch[:-1]\n",
    "            x_a = Variable(x[0].float().type(DTYPE), requires_grad=False).squeeze()\n",
    "            x_v = Variable(x[1].float().type(DTYPE), requires_grad=False).squeeze()\n",
    "            x_t = Variable(x[2].float().type(DTYPE), requires_grad=False)\n",
    "            y = Variable(batch[-1].view(-1, 1).float().type(DTYPE), requires_grad=False)\n",
    "            output_test = best_model(x_a, x_v, x_t)\n",
    "            loss_test = criterion(output_test, y)\n",
    "            test_loss = loss_test.data[0]\n",
    "        output_test = output_test.cpu().data.numpy().reshape(-1)\n",
    "        y = y.cpu().data.numpy().reshape(-1)\n",
    "\n",
    "        test_binacc = accuracy_score(output_test>=0, y>=0)\n",
    "        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y>=0, output_test>=0, average='binary')\n",
    "        test_septacc = (output_test.round() == y.round()).mean()\n",
    "\n",
    "        # compute the correlation between true and predicted scores\n",
    "        test_corr = np.corrcoef([output_test, y])[0][1]  # corrcoef returns a matrix\n",
    "        test_loss = test_loss / len(test_set)\n",
    "\n",
    "        display(test_loss, test_binacc, test_precision, test_recall, test_f1, test_septacc, test_corr)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS = argparse.ArgumentParser()\n",
    "OPTIONS.add_argument('--dataset', dest='dataset', type=str, default='MOSI')\n",
    "OPTIONS.add_argument('--epochs', dest='epochs', type=int, default=50)\n",
    "OPTIONS.add_argument('--batch_size', dest='batch_size', type=int, default=32)\n",
    "OPTIONS.add_argument('--patience', dest='patience', type=int, default=20)\n",
    "OPTIONS.add_argument('--cuda', dest='cuda', type=bool, default=False)\n",
    "OPTIONS.add_argument('--model_path', dest='model_path',\n",
    "                         type=str, default='models')\n",
    "OPTIONS.add_argument('--max_len', dest='max_len', type=int, default=20)\n",
    "PARAMS = vars(OPTIONS.parse_args())\n",
    "main(PARAMS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
